{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import SimpleITK as sitk\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[b'ObjectType = Image\\n', b'NDims = 3\\n', b'DimSize = 512 512 121\\n', b'ElementSpacing = 0.625 0.625 2.5\\n', b'Offset = 0 0 0\\n', b'TransformMatrix = 1 0 0 0 1 0 0 0 1\\n', b'ElementType = MET_SHORT\\n', b'BinaryData = True\\n', b'BinaryDataByteOrderMSB = false\\n', b'ElementDataFile = /home/jseia/Desktop/MAIA/classes/spain/mira/final_project/mira_final_project/data/dir_lab_copd/copd1/copd1_eBHCT.img\\n']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import argparse\n",
    "import os\n",
    "import tempfile\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Read the image using both big and little endian\n",
    "image = read_raw_sitk(\n",
    "    binary_file_name='/home/jseia/Desktop/MAIA/classes/spain/mira/final_project/mira_final_project/data/dir_lab_copd/copd1/copd1_eBHCT.img',\n",
    "    image_size=(512, 512, 121),\n",
    "    sitk_pixel_type=sitk.sitkInt16,\n",
    "    big_endian='false',\n",
    "    image_spacing=(0.625, 0.625, 2.5),\n",
    "    image_origin=None,\n",
    ")\n",
    "\n",
    "sitk.WriteImage(image, '/home/jseia/Desktop/MAIA/classes/spain/mira/final_project/mira_final_project/data/dir_lab_copd/copd1/copd1_eBHCT.nii')\n",
    "\n",
    "# if \"SITK_NOSHOW\" not in os.environ:\n",
    "#     sitk.Show(image, \"raw converted\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "        data_setting['ext'] = '.mha'\n",
    "        data_setting['ImageByte'] = 2                   # equals to sitk.sitkInt16 , we prefer not to import sitk in setting_utils\n",
    "        data_setting['types'] = ['iBHCT', 'eBHCT']      # for eg: 'Fixed' or 'Moving'\n",
    "        data_setting['expPrefix'] = 'copd'              # for eg: case\n",
    "        data_setting['DefaultPixelValue'] = -2048       # The pixel value when a transformed pixel is outside of the image\n",
    "        data_setting['VoxelSize'] = [1, 1, 1]\n",
    "        data_setting['AffineRegistration'] = True\n",
    "        data_setting['UnsureLandmarkAvailable'] = False\n",
    "        data_setting['CNList'] = [i for i in range(1, 11)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = Path('__file__').resolve().parent\n",
    "for "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sitk.ReadImage()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name '__file__' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/jseia/Desktop/MAIA/classes/spain/mira/final_project/mira_final_project/notebooks/dev_dataset.ipynb Cell 7\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/jseia/Desktop/MAIA/classes/spain/mira/final_project/mira_final_project/notebooks/dev_dataset.ipynb#X12sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mprint\u001b[39m(Path(\u001b[39m__file__\u001b[39;49m)\u001b[39m.\u001b[39mresolve()\u001b[39m.\u001b[39mparent)\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/jseia/Desktop/MAIA/classes/spain/mira/final_project/mira_final_project/notebooks/dev_dataset.ipynb#X12sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mprint\u001b[39m(Path(\u001b[39m__file__\u001b[39m)\u001b[39m.\u001b[39mresolve()\u001b[39m.\u001b[39mparent\u001b[39m.\u001b[39mparent)\n",
      "\u001b[0;31mNameError\u001b[0m: name '__file__' is not defined"
     ]
    }
   ],
   "source": [
    "print(Path(__file__).resolve().parent)\n",
    "print(Path(__file__).resolve().parent.parent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('/home/jseia/Desktop/MAIA/classes/spain/mira/final_project/mira_final_project/notebooks/__file__')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "data_path = Path('__file__').resolve().parent\n",
    "# data_path = data_path / 'data' / 'dir_lab_copd'\n",
    "data_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_37708/3313859526.py:3: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  a = pd.read_csv(p, header=None, sep='\\t ').values.astype(int)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "p = '/home/jseia/Desktop/MAIA/classes/spain/mira/final_project/mira_final_project/data/dir_lab_copd_raw/copd1/copd1_300_eBH_xyz_r1.txt'\n",
    "a = pd.read_csv(p, header=None, sep='\\t ').values.astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "b = np.zeros((512, 512, 121))\n",
    "b[a[:, 0], a[:, 1], a[:, 2]] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0.])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b[194, 257, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from typing import List\n",
    "\n",
    "data_path = Path('__file__').resolve().parent\n",
    "data_path = data_path / 'data' / 'dir_lab_copd'\n",
    "\n",
    "class DirLabCOPD():\n",
    "    def __init__(\n",
    "        self,\n",
    "        data_path: Path,\n",
    "        cases: List[str] = ['all'],\n",
    "        partitions: List[str] = ['train', 'test'],\n",
    "        phases: List[str] = ['i', 'e'],\n",
    "        use_ie_as_one: bool = True,\n",
    "    ):\n",
    "        self.data_path = data_path\n",
    "        self.cases = cases\n",
    "        self.partitions = partitions\n",
    "        self.phases = phases\n",
    "        \n",
    "        # 1,2) reading image:----------------------------------------------------------------\n",
    "        fid = open(im_img_address, 'rb')\n",
    "        im_data = np.fromfile(fid, np.int16)\n",
    "        image_old = im_data.reshape(dirlab_header['case' + str(cn)]['Size'][::-1])\n",
    "        image_old = np.flip(image_old, axis=0)  # The superior-inferior axis needs to be flipped\n",
    "        origin = [0, 0, 0]\n",
    "        image = copy.deepcopy(image_old)\n",
    "        # reading landmarks:\n",
    "        for ii, index_tr_old_address in enumerate(index_tr_old_address_list):\n",
    "            index_tr_new_address = index_tr_new_address_list[ii]\n",
    "            index_elx_new_address = index_elx_new_address_list[ii]\n",
    "            point_tr_new_address = point_tr_new_address_list[ii]\n",
    "            point_elx_new_address = point_elx_new_address_list[ii]\n",
    "            if os.path.isfile(index_tr_old_address):\n",
    "                index_tr_old_raw = np.loadtxt(index_tr_old_address)\n",
    "                # 4a&b) The superior-inferior axis is flipped. be careful about that indices start at 1. after converting to zero-start,\n",
    "                #  there is no -1 in the SI direction.\n",
    "\n",
    "                index_tr_old = np.array([[index_tr_old_raw[i, 0] - 1,\n",
    "                                          index_tr_old_raw[i, 1] - 1,\n",
    "                                          image_old.shape[0] - index_tr_old_raw[i, 2]]\n",
    "                                         for i in range(index_tr_old_raw.shape[0])])\n",
    "\n",
    "                # 3) remove empty slices only in DIR-Lab_COPD-----------------------------------------\n",
    "                if data == 'DIR-Lab_COPD':\n",
    "                    image, slices_to_remove = remove_empty_slices(image_old)\n",
    "                    print(im_img_name + ' slices are removed: ' + str(slices_to_remove))\n",
    "                    shift_indices = len(slices_to_remove)\n",
    "                    shift_world = shift_indices * dirlab_header['case' + str(cn)]['Spacing'][2]\n",
    "                    origin[2] = shift_world\n",
    "\n",
    "                    # 4c) change indices of landmarks based on the removed slices\n",
    "                    index_tr_new = [[index_tr_old[i, 0], index_tr_old[i, 1], index_tr_old[i, 2] - shift_indices] for i in range(index_tr_old.shape[0])]\n",
    "                else:\n",
    "                    index_tr_new = index_tr_old.copy()\n",
    "\n",
    "                np.savetxt(index_tr_new_address, index_tr_new, fmt='%d')\n",
    "                point_tr_new = ip.index_to_world(index_tr_new, spacing=dirlab_header['case' + str(cn)]['Spacing'], origin=origin)\n",
    "                np.savetxt(point_tr_new_address, point_tr_new, fmt='%-9.3f')\n",
    "                open_text = open(index_tr_new_address, \"r\")\n",
    "                number_of_landmarks = index_tr_new.shape[0]\n",
    "                with open(index_elx_new_address, \"w\") as open_elx:\n",
    "                    open_elx.write('index \\n')\n",
    "                    open_elx.write(str(number_of_landmarks) + ' \\n')\n",
    "                    open_elx.write(open_text.read())\n",
    "                open_text.close()\n",
    "\n",
    "                open_text = open(point_tr_new_address, \"r\")\n",
    "                with open(point_elx_new_address, \"w\") as open_elx:\n",
    "                    open_elx.write('point \\n')\n",
    "                    open_elx.write(str(number_of_landmarks) + ' \\n')\n",
    "                    open_elx.write(open_text.read())\n",
    "                open_text.close()\n",
    "\n",
    "        # 5) normalize the intensity\n",
    "        image = image - 1024  # we are not sure about the slope and intercept.\n",
    "\n",
    "        # 6) set the outside value to -2048\n",
    "        image[image == -3024] = -2048\n",
    "        image_sitk = ip.array_to_sitk(image, spacing=dirlab_header['case' + str(cn)]['Spacing'], origin=origin)\n",
    "        sitk.WriteImage(image_sitk, im_mha_address)\n",
    "        print('case' + str(cn) + ' type' + str(type_im) + ' is done..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import os\n",
    "import numpy as np\n",
    "import SimpleITK as sitk\n",
    "import functions.image.image_processing as ip\n",
    "\n",
    "\n",
    "def img_converter(data_folder, data, type_im, cn, ext='.mha', mha_folder_name='mha', point_folder_name='points'):\n",
    "    \"\"\"\n",
    "    convert img images to mha.\n",
    "    reading image:\n",
    "    1) Size and voxel spacing of the images are available at https://www.dir-lab.com/ReferenceData.html\n",
    "    2) The superior-inferior axis needs to be flipped\n",
    "    3) Empty slices will be removed\n",
    "        copd1_eBHCT.mha slice 0:1\n",
    "        copd2_eBHCT.mha slice 0:6\n",
    "        copd3_eBHCT.mha slice 0:9\n",
    "        copd4_eBHCT.mha slice 0:9\n",
    "        copd5_eBHCT.mha slice NA\n",
    "        copd6_eBHCT.mha slice 0:2\n",
    "        copd7_eBHCT.mha slice 0:9\n",
    "        copd8_eBHCT.mha slice 0:7\n",
    "        copd9_eBHCT.mha slice 0:19\n",
    "        copd10_iBHCT.mah slice 0\n",
    "    4) Index modification:\n",
    "        4a) The superior-inferior axis are flipped. The reason is that to make it more similar to SPREAD study.\n",
    "        4b) The indices start at 1. We like them to start at 0.\n",
    "        4c) change indices of landmarks based on the removed slices\n",
    "    5) Normalize the intensity by subtracting by -1024\n",
    "    6) Set the outside value to -2048\n",
    "    :param ext\n",
    "    :param cn:\n",
    "    :param type_im\n",
    "    :param data_folder\n",
    "    :param data\n",
    "    :param mha_folder_name\n",
    "    :param point_folder_name\n",
    "    :return: converted mha image and converted landmark files:\n",
    "        example: \n",
    "            copd1_eBHCT.mha\n",
    "            copd1_300_eBH_world_r1_tr.txt:  landmarks in world coordinate (truncated)\n",
    "            copd1_300_eBH_world_r1_elx.txt: landmarks in world coordinate with two additional lines for elastix\n",
    "            copd1_300_eBH_xyz_r1_tr.txt:    landmark in indices\n",
    "            copd1_300_eBH_xyz_r1_elx.txt:   landmark in indices with two additional lines for elastix\n",
    "    \"\"\"\n",
    "\n",
    "    if not os.path.isfile(im_mha_address):\n",
    "        \n",
    "\n",
    "\n",
    "def remove_empty_slices(image):\n",
    "    slices_to_remove = []\n",
    "    for slice_index in range(np.shape(image)[0]):\n",
    "        if np.sum(image[slice_index, :, :]) == 0:\n",
    "            slices_to_remove.append(slice_index)\n",
    "    slices_all = [i for i in range(np.shape(image)[0])]\n",
    "    slices_to_keep = [i for i in slices_all if i not in slices_to_remove]\n",
    "    image_cropped = image[slices_to_keep, :, :]\n",
    "\n",
    "    return image_cropped, slices_to_remove\n",
    "\n",
    "\n",
    "def dirlab_copd_header():\n",
    "    \"\"\"\n",
    "    size and voxel spacing of the images are available at https://www.dir-lab.com/ReferenceData.html\n",
    "    \"\"\"\n",
    "    dirlab_info = dict()\n",
    "    for cn in range(1, 11):\n",
    "        dirlab_info['case' + str(cn)] = {}\n",
    "    dirlab_info['case1']['Size'] = [512, 512, 121]\n",
    "    dirlab_info['case2']['Size'] = [512, 512, 102]\n",
    "    dirlab_info['case3']['Size'] = [512, 512, 126]\n",
    "    dirlab_info['case4']['Size'] = [512, 512, 126]\n",
    "    dirlab_info['case5']['Size'] = [512, 512, 131]\n",
    "    dirlab_info['case6']['Size'] = [512, 512, 119]\n",
    "    dirlab_info['case7']['Size'] = [512, 512, 112]\n",
    "    dirlab_info['case8']['Size'] = [512, 512, 115]\n",
    "    dirlab_info['case9']['Size'] = [512, 512, 116]\n",
    "    dirlab_info['case10']['Size'] = [512, 512, 135]\n",
    "\n",
    "    dirlab_info['case1']['Spacing'] = [0.625, 0.625, 2.5]\n",
    "    dirlab_info['case2']['Spacing'] = [0.645, 0.645, 2.5]\n",
    "    dirlab_info['case3']['Spacing'] = [0.652, 0.652, 2.5]\n",
    "    dirlab_info['case4']['Spacing'] = [0.590, 0.590, 2.5]\n",
    "    dirlab_info['case5']['Spacing'] = [0.647, 0.647, 2.5]\n",
    "    dirlab_info['case6']['Spacing'] = [0.633, 0.633, 2.5]\n",
    "    dirlab_info['case7']['Spacing'] = [0.625, 0.625, 2.5]\n",
    "    dirlab_info['case8']['Spacing'] = [0.586, 0.586, 2.5]\n",
    "    dirlab_info['case9']['Spacing'] = [0.644, 0.644, 2.5]\n",
    "    dirlab_info['case10']['Spacing'] = [0.742, 0.742, 2.5]\n",
    "\n",
    "    return dirlab_info\n",
    "\n",
    "\n",
    "def dirlab_4dct_header():\n",
    "    \"\"\"\n",
    "    size and voxel spacing of the images are available at https://www.dir-lab.com/ReferenceData.html\n",
    "    \"\"\"\n",
    "    dirlab_info = dict()\n",
    "    for cn in range(1, 11):\n",
    "        dirlab_info['case' + str(cn)] = {}\n",
    "    dirlab_info['case1']['Size'] = [256, 256, 94]\n",
    "    dirlab_info['case2']['Size'] = [256, 256, 112]\n",
    "    dirlab_info['case3']['Size'] = [256, 256, 104]\n",
    "    dirlab_info['case4']['Size'] = [256, 256, 99]\n",
    "    dirlab_info['case5']['Size'] = [256, 256, 106]\n",
    "    dirlab_info['case6']['Size'] = [512, 512, 128]\n",
    "    dirlab_info['case7']['Size'] = [512, 512, 136]\n",
    "    dirlab_info['case8']['Size'] = [512, 512, 128]\n",
    "    dirlab_info['case9']['Size'] = [512, 512, 128]\n",
    "    dirlab_info['case10']['Size'] = [512, 512, 120]\n",
    "\n",
    "    dirlab_info['case1']['Spacing'] = [0.97, 0.97, 2.5]\n",
    "    dirlab_info['case2']['Spacing'] = [1.16, 1.16, 2.5]\n",
    "    dirlab_info['case3']['Spacing'] = [1.15, 1.15, 2.5]\n",
    "    dirlab_info['case4']['Spacing'] = [1.13, 1.13, 2.5]\n",
    "    dirlab_info['case5']['Spacing'] = [1.10, 1.10, 2.5]\n",
    "    dirlab_info['case6']['Spacing'] = [0.97, 0.97, 2.5]\n",
    "    dirlab_info['case7']['Spacing'] = [0.97, 0.97, 2.5]\n",
    "    dirlab_info['case8']['Spacing'] = [0.97, 0.97, 2.5]\n",
    "    dirlab_info['case9']['Spacing'] = [0.97, 0.97, 2.5]\n",
    "    dirlab_info['case10']['Spacing'] = [0.97, 0.97, 2.5]\n",
    "\n",
    "    return dirlab_info\n",
    "\n",
    "\n",
    "def main():\n",
    "    data = 'DIR-Lab_4D'\n",
    "    data_folder = 'E:/PHD/Database/'\n",
    "    for cn in range(6, 11):\n",
    "        for type_im in [0, 5]:\n",
    "            img_converter(data_folder=data_folder, data=data, type_im=type_im, cn=cn)\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "14959ff415bed1253b118a8be2fda54c841b345c785805f1879b209cfe8cfa79"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
